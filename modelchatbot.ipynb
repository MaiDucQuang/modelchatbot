{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel(\"your_data_file.xlsx\")\n",
    "questions = df[\"question\"].tolist()\n",
    "answers = df[\"answer\"].tolist()\n",
    "\n",
    "tokenized_questions = [word_tokenize(question) for question in questions]\n",
    "tokenized_answers = [word_tokenize(answer) for answer in answers]\n",
    "\n",
    "max_length = max(max(len(seq) for seq in tokenized_questions), max(len(seq) for seq in tokenized_answers))\n",
    "padded_questions = pad_sequences(tokenized_questions, maxlen=max_length, padding='post')\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=max_length, padding='post')\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_length),\n",
    "    tf.keras.layers.LSTM(256),\n",
    "    tf.keras.layers.Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_questions, test_questions, train_answers, test_answers = train_test_split(padded_questions, padded_answers, test_size=0.2)\n",
    "model.fit(train_questions, train_answers, epochs=20)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_questions, test_answers, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "input_question = \"Bạn là ai?\"\n",
    "input_sequence = pad_sequences([word_tokenize(input_question)], maxlen=max_length, padding='post')\n",
    "predicted_sequence = model.predict(input_sequence)\n",
    "predicted_answer = tokenizer.sequences_to_texts([predicted_sequence.argmax(axis=-1)])\n",
    "\n",
    "print(f\"Input Question: {input_question}\")\n",
    "print(f\"Predicted Answer: {predicted_answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
